%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Make sure to set your name, legi number and url to the right git branch.
\newcommand{\hmwkAuthorName}{Sveinn PÃ¡lsson} % Your name
\newcommand{\hmwkAuthorLegi}{16-931-149} % Your name
\newcommand{\hmwkGitBranch}{https://gitlab.vis.ethz.ch/vwegmayr/slt-coding-exercises/tree/16-931-149/1\_locally\_linear\_embedding} % Your name
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%	Skip this
%----------------------------------------------------------------------------------------

\documentclass{article}

\usepackage{float}
\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage{graphicx} % Required to insert images
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template

% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in 

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{\hmwkAuthorName} % Top left header
\chead{\hmwkClass\ \hmwkTitle} % Top center header
\rhead{\firstxmark} % Top right header
\lfoot{\lastxmark} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{Page\ \thepage\ of\ \pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs

%----------------------------------------------------------------------------------------
%	DOCUMENT STRUCTURE COMMANDS
%	Skip this
%----------------------------------------------------------------------------------------

% Header and footer for when a page split occurs within a problem environment
\newcommand{\enterProblemHeader}[1]{
\nobreak\extramarks{#1}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
}

% Header and footer for when a page split occurs between problem environments
\newcommand{\exitProblemHeader}[1]{
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1}{}\nobreak
}

\setcounter{secnumdepth}{0} % Removes default section numbers
\newcounter{homeworkProblemCounter} % Creates a counter to keep track of the number of problems

\newcommand{\homeworkProblemName}{}
\newenvironment{homeworkProblem}[1][Problem \arabic{homeworkProblemCounter}]{ % Makes a new environment called homeworkProblem which takes 1 argument (custom name) but the default is "Problem #"
\stepcounter{homeworkProblemCounter} % Increase counter for number of problems
\renewcommand{\homeworkProblemName}{#1} % Assign \homeworkProblemName the name of the problem
\section{\homeworkProblemName} % Make a section in the document with the custom problem count
\enterProblemHeader{\homeworkProblemName} % Header and footer within the environment
}{
\exitProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

\newcommand{\problemAnswer}[1]{ % Defines the problem answer command with the content as the only argument
\noindent\framebox[\columnwidth][c]{\begin{minipage}{0.98\columnwidth}#1\end{minipage}} % Makes the box around the problem answer and puts the content inside
}

\newcommand{\homeworkSectionName}{}
\newenvironment{homeworkSection}[1]{ % New environment for sections within homework problems, takes 1 argument - the name of the section
\renewcommand{\homeworkSectionName}{#1} % Assign \homeworkSectionName to the name of the section from the environment argument
\subsection{\homeworkSectionName} % Make a subsection with the custom name of the subsection
\enterProblemHeader{\homeworkProblemName\ [\homeworkSectionName]} % Header and footer within the environment
}{
\enterProblemHeader{\homeworkProblemName} % Header and footer after the environment
}
   
%----------------------------------------------------------------------------------------
%	NAME AND CLASS SECTION
%	Skip this
%----------------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{Locally Linear Embedding} % Assignment title
\newcommand{\hmwkDueDate}{Monday,\ March\ 6th,\ 2017} % Due date
\newcommand{\hmwkClass}{SLT coding exercise\ \#1} % Course/class
\newcommand{\hmwkClassTime}{Mo 16:15} % Class/lecture time
\newcommand{\hmwkClassInstructor}{} % Teacher/lecturer

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%	Skip this
%----------------------------------------------------------------------------------------

\title{
\vspace{2in}
\textmd{\small{\hmwkClass}}\\
\textmd{\textbf{\hmwkTitle}}\\
\small{https://gitlab.vis.ethz.ch/vwegmayr/slt-coding-exercises}\\
\normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate}
%\vspace{0.1in}\large{\textit{\hmwkClassInstructor\ \hmwkClassTime}}
\vspace{3in}
}

\author{
\hmwkAuthorName\\
\hmwkAuthorLegi
}

\date{ } % Insert date here if you want it to appear below your name

\begin{document}

\maketitle

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS
%	Skip this
%----------------------------------------------------------------------------------------

%\setcounter{tocdepth}{1} % Uncomment this line if you don't want subsections listed in the ToC

\newpage
\tableofcontents
\newpage

%----------------------------------------------------------------------------------------
%	SECTIONS
%	Now you are in the right hood
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}[The Model]

\problemAnswer{ % Answer
Suppose the data consists of $N$ real valued vectors $X_i$, each of dimensionality D. For each data point we find its K nearest neighbors as measured by Euclidean distance. For each data point $X_i$ we want to find weights $W_{ij}$ for each of the K nearest neighbor such that we minimize the reconstruction error function
$$\mathcal{E}(W) = \sum_i\bigg\vert X_i - \sum_jW_{ij}X_j\bigg\vert^2$$

subject to two constraints: first, that each data point is reconstructed only from its neigbors, enforcing $W_{ij} = 0$ if $X_j$ does not belong to this set; second, that the rows of the weight matrix sum to one.

We choose a $d<<D$ and find d dimensional coordinates $Y_i$ for each data point $X_i$. We do this by minimizing the embedding cost function
$$\Phi(Y) = \sum_i\bigg\vert Y_i - \sum_j W_{ij}Y_j\bigg\vert^2$$

}

\end{homeworkProblem}
\clearpage

%----------------------------------------------------------------------------------------
\begin{homeworkProblem}[The Questions]

\problemAnswer{
Answer b:
Yes, some clusters appear. See examples in figure 1 below.
}

\begin{figure}[h]
\includegraphics[scale=0.4]{fig_2d_8k.png}
\includegraphics[scale=0.4]{fig_3d_8k.png}

\caption{There are some visible clusters in the results.}
\end{figure}

\problemAnswer{
Answer c:
We can see that the diagonal elements are all non-zero.

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{Mplot.png}
\caption{Plotting part of the matrix M}
\end{figure}
}


\vspace{10pt}
\problemAnswer{ % Answer
Answer d:
When we change K, the number of nearest neighbors we can see some differences. If we only use 1 neighbor for each data point we can see that no visible clusters form (figure 3). Then as we increase the number of nearest neighbors we start seeing clusters even with K=3 (figure 4). The clusters seem to become more clear when we increase K. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{fig_2d_1k.png}
\caption{Using only 1 nearest neighbor}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{fig_2d_3k.png}
\caption{Using 3 nearest neighbor}
\end{figure}
}
\problemAnswer{
Figures 5,6 and 7 show the use of 7 nearest neighbors with Euclidean, Hamming and Chebyshev distance metrics respectively.

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{fig_2d_7k.png}
\caption{K=7, Euclidean distance}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{fig_2d_7k_hamming.png}
\caption{K=7, Hamming distance}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{fig_2d_7k_cheby.png}
\caption{K=7, Chebyshev distance}
\end{figure}
}
\problemAnswer{
Answer e:
One method would be to find the point's K nearest neighbors in the embedding space and find the reconstruction weights as in the high dimensional space. Then use these K nearest neighbors and weights in the high dimensional space to reconstruct the data-point. This depends highly on the dimensionality of the embedding space, it works better for higher dimensions.
See figure 8 where a data point is reconstructed using this method. The figures also show the original image for comparison.

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{rec_220.png}
\caption{Reconstruction of a data point. Upper image shows the reconstruction, the lower image shows the original}
\end{figure}

}
\end{homeworkProblem}
\clearpage

%----------------------------------------------------------------------------------------
\begin{homeworkProblem}[The Implementation]


\vspace{10pt}
\problemAnswer{ % Answer
The implementation involves finding eigenvectors of a very large matrix. For the MNIST dataset this could mean a 60000 by 60000 matrix which my implementation would take a very long time to compute. When answering the questions in the previous questions I used only 5000 samples which my implementation of LLE took only about 10 seconds to solve. 
Link to my git branch: https://gitlab.vis.ethz.ch/vwegmayr/slt-coding-exercises/tree/16-931-149/1\_locally\_linear\_embedding

}
\end{homeworkProblem}
\clearpage

%----------------------------------------------------------------------------------------
\begin{homeworkProblem}[Your Page]


\vspace{10pt}
\problemAnswer{ % Answer

\hmwkGitBranch % defined in line 5
}
\end{homeworkProblem}
\clearpage

\end{document}

